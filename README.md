# ğŸ¤– Automatos AI - Comprehensive Testing Suite

[![API Status](https://img.shields.io/badge/API-Live-brightgreen)](https://api.automatos.app/health)
[![Tests](https://img.shields.io/badge/Tests-Comprehensive-blue)](#test-coverage)
[![License](https://img.shields.io/badge/License-MIT-yellow)](#license)

A comprehensive testing framework for the Automatos AI multi-agent orchestration platform. This repository provides thorough API testing, user journey validation, and system health monitoring.

## ğŸ¯ Purpose

This testing suite validates the complete Automatos AI ecosystem, including:
- **Agent Management**: Lifecycle, skills, and execution testing
- **Workflow Orchestration**: Pattern management and execution flows  
- **Document Management**: Processing, analytics, and retrieval
- **Context Engineering**: RAG system and vector embeddings
- **Performance Analytics**: System metrics and monitoring

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Network access to `https://api.automatos.app`
- Required Python packages (see requirements.txt)

### Installation
```bash
git clone git@github.com:AutomatosAI/automatos-testing.git
cd automatos-testing
pip install -r requirements.txt
```

### Run All Tests
```bash
cd testing_suites/comprehensive_5phase
python3 run_all_tests.py
```

### Run Individual Phase Tests
```bash
# Agent Management
cd testing_suites/comprehensive_5phase/phase1_agent_management/scripts
python3 comprehensive_agent_test.py

# Workflow Orchestration  
cd testing_suites/comprehensive_5phase/phase2_workflow_orchestration/scripts
python3 comprehensive_workflow_test.py

# Document Management
cd testing_suites/comprehensive_5phase/phase3_document_management/scripts
python3 comprehensive_document_test.py

# Context Engineering
cd testing_suites/comprehensive_5phase/phase4_context_engineering/scripts
python3 comprehensive_context_test.py

# Performance Analytics
cd testing_suites/comprehensive_5phase/phase5_performance_analytics/scripts
python3 comprehensive_performance_test.py
```

## ğŸ“Š Test Coverage

| Test Phase | Status | Coverage | Endpoints Tested |
|------------|--------|----------|------------------|
| **Agent Management** | âœ… Ready | Agent CRUD, Skills, Execution | `/api/agents/*` |
| **Workflow Orchestration** | âœ… Ready | Patterns, Templates, Execution | `/api/workflows/*` |
| **Document Management** | âœ… Ready | Upload, Processing, Analytics | `/api/documents/*` |
| **Context Engineering** | âœ… Ready | RAG, Embeddings, Retrieval | `/api/context/*` |
| **Performance Analytics** | âœ… Ready | Metrics, Health, Monitoring | `/api/system/*` |

### Success Criteria
- **70% API Success Rate** required for each phase to pass
- **Real API validation** with no fake success reporting
- **Comprehensive logging** of all requests and responses
- **Professional result reporting** in JSON and Markdown formats

## ğŸŒ API Endpoints

### Primary Endpoint
- **HTTPS**: `https://api.automatos.app` (Recommended)
- **Backup**: `http://206.81.0.227:8000` (Direct IP access)

### Health Check
```bash
curl https://api.automatos.app/health
# Expected: {"status":"healthy","service":"automotas-ai-api"}
```

### Key Endpoints Tested
```bash
# Agent Management
GET  /api/agents/              # List all agents
POST /api/agents/              # Create new agent
GET  /api/agents/{id}          # Get agent details
POST /api/agents/{id}/skills   # Add agent skills

# System Health
GET  /health                   # Basic health check
GET  /api/system/health        # Detailed health info
GET  /api/system/metrics       # Performance metrics

# Context & Analytics
GET  /api/context/stats        # Context statistics
GET  /api/workflows/active     # Active workflows
GET  /api/documents/analytics/overview  # Document analytics
```

## ğŸ“ Repository Structure

```
automatos-testing/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ TESTING_INDEX.md                   # Testing overview
â”œâ”€â”€ .gitignore                         # Git ignore file
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ testing_suites/
â”‚   â”œâ”€â”€ comprehensive_5phase/          # Main test suite
â”‚   â”‚   â”œâ”€â”€ run_all_tests.py          # Master test runner
â”‚   â”‚   â”œâ”€â”€ shared_config.yaml        # Test configuration
â”‚   â”‚   â”œâ”€â”€ shared_utils.py           # Common utilities
â”‚   â”‚   â”œâ”€â”€ phase1_agent_management/
â”‚   â”‚   â”œâ”€â”€ phase2_workflow_orchestration/
â”‚   â”‚   â”œâ”€â”€ phase3_document_management/
â”‚   â”‚   â”œâ”€â”€ phase4_context_engineering/
â”‚   â”‚   â””â”€â”€ phase5_performance_analytics/
â”‚   â””â”€â”€ journey_tests/                 # User journey tests
â”œâ”€â”€ results/                           # Test results (generated)
â”œâ”€â”€ logs/                             # Execution logs (generated)
â””â”€â”€ scripts/                          # Utility scripts
```

## ğŸ”§ Configuration

### API Configuration
Edit `testing_suites/comprehensive_5phase/shared_config.yaml`:

```yaml
api:
  base_url: "https://api.automatos.app"
  fallback_urls:
    - "http://206.81.0.227:8000"
  timeout: 30
  max_retries: 3

performance:
  success_threshold: 0.7  # 70% success rate required
```

## ğŸ“ˆ Understanding Results

### Test Output Locations
- **Master Reports**: `MASTER_SUMMARY_*.md` and `MASTER_TEST_REPORT_*.json`
- **Individual Results**: `phase*/results/*.json`
- **API Logs**: `phase*/responses/*.json`
- **Execution Logs**: `*.log` files with timestamps

### Success Determination
Tests use **real API validation** with these criteria:
- **API Response Validation**: Must receive valid HTTP responses
- **Content Verification**: Response data must be properly formatted
- **Performance Thresholds**: Response times under 1000ms preferred
- **Success Rate**: 70% of API calls must succeed for phase to pass

### Sample Results
```bash
ğŸ“Š AGENT MANAGEMENT TESTING COMPLETED
ğŸ“Š Total API Calls: 15
âœ… Successful: 12
âŒ Failed: 3
ğŸ“ˆ Success Rate: 80.0%
ğŸ¯ Required Threshold: 70.0%
âœ… AGENT MANAGEMENT TESTS PASSED - Meeting minimum threshold
```

## ğŸš¨ Known Issues & Status

### Currently Working
- âœ… Agent listing and details (`/api/agents/*`)
- âœ… System health and metrics (`/api/system/*`)
- âœ… Context statistics (`/api/context/stats`)
- âœ… Workflow active status (`/api/workflows/active`)
- âœ… Document analytics (`/api/documents/analytics/*`)

### Known Limitations
- âš ï¸ Some workflow pattern endpoints return 404
- âš ï¸ File upload testing limited (multipart uploads)
- âš ï¸ Some advanced context operations not implemented

## ğŸ¤ Contributing

### Running Tests Locally
1. Clone the repository
2. Install dependencies: `pip install -r requirements.txt`  
3. Run tests: `python3 run_all_tests.py`
4. Review results in generated reports

### Reporting Issues
- Use GitHub Issues for bug reports
- Include test logs and error messages
- Specify which phase/endpoint failed
- Provide system information (Python version, OS)

## ğŸ“œ License

MIT License - see LICENSE file for details.

## ğŸ”— Related Projects

- [Automatos AI Platform](https://automatos.app)
- [API Documentation](https://api.automatos.app/docs)

---

**Note**: This testing suite provides real validation of the Automatos AI platform. Results reflect actual system functionality and API health. No fake or simulated results are generated.